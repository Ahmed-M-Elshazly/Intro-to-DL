{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RHQXZ6eWu_d"
      },
      "outputs": [],
      "source": [
        "############## No Fine-Tuning #################\n",
        "import cvxpy as cp\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from transformers import BertTokenizer, BertModel\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# 1) Convex oracle: solve the LP with default solver\n",
        "def generate_optimal_schedule(price, P_h, E_h, peak_limit):\n",
        "    N, H = len(price), len(P_h)\n",
        "    X = cp.Variable((N, H))\n",
        "    power = cp.multiply(X, P_h.reshape(1, H))\n",
        "    cost = cp.sum(cp.multiply(price.reshape(N, 1), power)) / 1000.0\n",
        "    constraints = [\n",
        "        cp.sum(power, axis=0) >= E_h,\n",
        "        cp.sum(power, axis=1) <= peak_limit,\n",
        "        X >= 0, X <= 1\n",
        "    ]\n",
        "    prob = cp.Problem(cp.Minimize(cost), constraints)\n",
        "    prob.solve(verbose=False)\n",
        "    # Round to 0/1\n",
        "    return X.value.astype(float)\n",
        "\n",
        "# 2) Structured Prompt Dataset\n",
        "class TSLSupervisedDatasetStructured(Dataset):\n",
        "    def __init__(self, n_samples, N, H):\n",
        "        self.prompts = []\n",
        "        self.targets = []\n",
        "        self.N, self.H = N, H\n",
        "        self.P_h = np.array([1000, 1500])  # Rated power for each appliance\n",
        "\n",
        "        # Define ranges for energy requirements (in Wh)\n",
        "        self.E_h_ranges = np.array([\n",
        "            [2000, 4000],  # Appliance 1 range\n",
        "            [4000, 8000]    # Appliance 2 range\n",
        "        ])\n",
        "\n",
        "        # Define the range for the peak limit (in Watts)\n",
        "        self.peak_range = (2000, 6000)\n",
        "\n",
        "        for _ in range(n_samples):\n",
        "            price = 0.05 + (0.2 - 0.05) * np.random.rand(N)\n",
        "            # Sample energy requirements randomly from the defined ranges\n",
        "            E_h = np.array([\n",
        "                np.random.randint(self.E_h_ranges[0, 0], self.E_h_ranges[0, 1]),\n",
        "                np.random.randint(self.E_h_ranges[1, 0], self.E_h_ranges[1, 1])\n",
        "            ])\n",
        "            # Sample a peak limit randomly from the given range for each sample\n",
        "            peak_limit = np.random.randint(*self.peak_range)\n",
        "            X_opt = generate_optimal_schedule(price, self.P_h, E_h, peak_limit)\n",
        "            self.prompts.append(self._build_prompt(price, E_h, peak_limit))\n",
        "            self.targets.append(torch.tensor(X_opt.flatten(), dtype=torch.float32))\n",
        "\n",
        "    def _build_prompt(self, price, E_h, peak_limit):\n",
        "        s = \"[Prices]\\n\" + \"\\n\".join(f\"Slot {i+1}: {p:.3f} $/kWh\" for i, p in enumerate(price))\n",
        "        s += \"\\n\\n[Appliances]\\n\"\n",
        "        for i, (pw, eg) in enumerate(zip(self.P_h, E_h), start=1):\n",
        "            s += (f\"Appliance {i}:\\n\"\n",
        "                  f\"  Rated Power: {pw/1000:.1f} kW\\n\"\n",
        "                  f\"  Energy Required: {eg/1000:.1f} kWh\\n\")\n",
        "        s += f\"\\n[Peak Limit]\\n{peak_limit/1000:.1f} kW\\n\"\n",
        "        s += \"\\n[Objective]\\nMinimize total electricity cost.\\n\"\n",
        "        s += f\"\\n[Output]\\nProvide a {self.N}x{self.H} schedule matrix.\"\n",
        "        return s\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.prompts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.prompts[idx], self.targets[idx]\n",
        "\n",
        "# 3) Model: BERT-base → logits\n",
        "class SupervisedTSLModel(nn.Module):\n",
        "    def __init__(self, N, H):\n",
        "        super().__init__()\n",
        "        self.tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "        hidden = self.bert.config.hidden_size\n",
        "        self.regressor = nn.Sequential(\n",
        "            nn.Linear(hidden, hidden // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden // 2, N * H)\n",
        "        )\n",
        "\n",
        "    def forward(self, prompts):\n",
        "        enc = self.tokenizer(prompts,\n",
        "                             padding=True,\n",
        "                             truncation=True,\n",
        "                             return_tensors=\"pt\")\n",
        "        device = next(self.bert.parameters()).device\n",
        "        enc = {k: v.to(device) for k, v in enc.items()}\n",
        "        out = self.bert(**enc).last_hidden_state[:, 0, :]  # CLS token representation\n",
        "        return self.regressor(out)\n",
        "\n",
        "# 4) Training with BCEWithLogitsLoss to get binary schedules\n",
        "def train_model(model, dataset, epochs=20, batch_size=16, lr=2e-5):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "    optim = AdamW(model.parameters(), lr=lr)\n",
        "    loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    for ep in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        running = 0.0\n",
        "        for prompts, targets in loader:\n",
        "            logits = model(prompts).to(device)\n",
        "            loss = loss_fn(logits, targets.to(device))\n",
        "            optim.zero_grad()\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            running += loss.item() * targets.size(0)\n",
        "        print(f\"Epoch {ep}/{epochs} — Avg Loss: {running/len(dataset):.6f}\")\n",
        "    return model\n",
        "\n",
        "# 5) Test & plot just stacked bars (binary schedules)\n",
        "def test_and_plot(model, tests=3, N=25):\n",
        "    P_h = np.array([1000, 1500])\n",
        "    # Define the same energy ranges as in training\n",
        "    E_h_ranges = np.array([\n",
        "        [2000, 4000],  # Appliance 1 range\n",
        "        [4000, 8000]   # Appliance 2 range\n",
        "    ])\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "    model.eval().to(device)\n",
        "\n",
        "    for t_i in range(1, tests + 1):\n",
        "        price = 0.05 + (0.2 - 0.05) * np.random.rand(N)\n",
        "        # Sample energy requirements randomly for testing\n",
        "        E_h = np.array([\n",
        "            np.random.randint(E_h_ranges[0, 0], E_h_ranges[0, 1]),\n",
        "            np.random.randint(E_h_ranges[1, 0], E_h_ranges[1, 1])\n",
        "        ])\n",
        "        # Sample a new peak limit from the defined range for testing\n",
        "        peak = np.random.randint(2000, 6000)\n",
        "\n",
        "        # Build the prompt using the randomized values\n",
        "        p = \"[Prices]\\n\" + \"\\n\".join(f\"Slot {i+1}: {v:.3f} $/kWh\" for i, v in enumerate(price))\n",
        "        p += \"\\n\\n[Appliances]\\n\"\n",
        "        for i, (pw, eg) in enumerate(zip(P_h, E_h), start=1):\n",
        "            p += (f\"Appliance {i}:\\n\"\n",
        "                  f\"  Rated Power: {pw/1000:.1f} kW\\n\"\n",
        "                  f\"  Energy Required: {eg/1000:.1f} kWh\\n\")\n",
        "        p += f\"\\n[Peak Limit]\\n{peak/1000:.1f} kW\\n\"\n",
        "        p += \"\\n[Objective]\\nMinimize total electricity cost.\\n\"\n",
        "        p += f\"\\n[Output]\\nProvide a {N}x2 schedule matrix.\"\n",
        "\n",
        "        # Predict using the model\n",
        "        with torch.no_grad():\n",
        "            enc = tokenizer([p], padding=True, truncation=True,\n",
        "                            return_tensors=\"pt\").to(device)\n",
        "            out = model.bert(**enc).last_hidden_state[:, 0, :]\n",
        "            logits = model.regressor(out)\n",
        "            probs = torch.sigmoid(logits).cpu().numpy()[0].reshape(N, 2)\n",
        "        bin_sched = probs.astype(float)\n",
        "\n",
        "        # Get the optimal schedule for comparison\n",
        "        opt_sched = generate_optimal_schedule(price, P_h, E_h, peak)\n",
        "\n",
        "        # Plot predicted binary schedule\n",
        "        t = np.arange(N)\n",
        "        fig, ax = plt.subplots(1, 1, figsize=(10, 3))\n",
        "        ax.bar(t, bin_sched[:, 0]*P_h[0], label=\"Appliance 1\")\n",
        "        ax.bar(t, bin_sched[:, 1]*P_h[1],\n",
        "               bottom=bin_sched[:, 0]*P_h[0], label=\"Appliance 2\")\n",
        "        ax.axhline(peak, color='r', ls='--', label=\"Peak Limit\")\n",
        "        ax.set_title(f\"LLM Binary Schedule (Test {t_i})\")\n",
        "        ax.set_xlabel(\"Time Slot\")\n",
        "        ax.set_ylabel(\"Power (W)\")\n",
        "        ax.legend(), ax.grid(True)\n",
        "        plt.show()\n",
        "\n",
        "        # Plot optimal schedule\n",
        "        fig, ax = plt.subplots(1, 1, figsize=(10, 3))\n",
        "        ax.bar(t, opt_sched[:, 0]*P_h[0], label=\"Appliance 1\")\n",
        "        ax.bar(t, opt_sched[:, 1]*P_h[1],\n",
        "               bottom=opt_sched[:, 0]*P_h[0], label=\"Appliance 2\")\n",
        "        ax.axhline(peak, color='r', ls='--', label=\"Peak Limit\")\n",
        "        ax.set_title(f\"Optimal Schedule (Test {t_i})\")\n",
        "        ax.set_xlabel(\"Time Slot\")\n",
        "        ax.set_ylabel(\"Power (W)\")\n",
        "        ax.legend(), ax.grid(True)\n",
        "        plt.show()\n",
        "\n",
        "        # Print cost summary\n",
        "        cost_pred = (price[:, None] * (bin_sched * P_h)/1000.0).sum()\n",
        "        cost_opt  = (price[:, None] * (opt_sched * P_h)/1000.0).sum()\n",
        "        print(f\"Test {t_i}: Pred Cost=${cost_pred:.2f}, Opt Cost=${cost_opt:.2f}, Gap=${cost_pred - cost_opt:.2f}\\n\")\n",
        "\n",
        "# 6) Entry point\n",
        "if __name__ == \"__main__\":\n",
        "    torch.cuda.empty_cache()\n",
        "    N, H = 25, 2\n",
        "\n",
        "    # Create dataset\n",
        "    ds = TSLSupervisedDatasetStructured(5000, N, H)\n",
        "\n",
        "    # Initialize model\n",
        "    model = SupervisedTSLModel(N, H)\n",
        "\n",
        "    # ✅ Freeze all BERT parameters\n",
        "    for param in model.bert.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # ✅ Print how many parameters will be trained\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(f\"Total Parameters: {total_params}\")\n",
        "    print(f\"Trainable Parameters: {trainable_params} (Only MLP head)\\n\")\n",
        "\n",
        "    # Train only the MLP\n",
        "    model = train_model(model, ds, epochs=30, batch_size=16, lr=2e-5)\n",
        "\n",
        "    # Run test-time prediction and visualization\n",
        "    test_and_plot(model, tests=5, N=N)\n"
      ]
    }
  ]
}