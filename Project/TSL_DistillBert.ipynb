{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrNXRXvZXODT"
      },
      "outputs": [],
      "source": [
        "import cvxpy as cp\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from transformers import DistilBertTokenizer, DistilBertModel\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# 1) Convex oracle (with optional guidance)\n",
        "def generate_optimal_schedule(price, P_h, E_h, peak_limit):\n",
        "    N, H = len(price), len(P_h)\n",
        "    X = cp.Variable((N, H))\n",
        "    power = cp.multiply(X, P_h.reshape(1, H))\n",
        "    cost = cp.sum(cp.multiply(price.reshape(N, 1), power)) / 1000.0\n",
        "    constraints = [\n",
        "        cp.sum(power, axis=0) >= E_h,\n",
        "        cp.sum(power, axis=1) <= peak_limit,\n",
        "        X >= 0, X <= 1\n",
        "    ]\n",
        "    prob = cp.Problem(cp.Minimize(cost), constraints)\n",
        "    prob.solve(verbose=False)\n",
        "    return X.value.astype(float)\n",
        "\n",
        "# 1b) Convex Oracle Guided by Model Output\n",
        "def generate_optimal_schedule_guided(price, P_h, E_h, peak_limit, guidance=None, lam=1.0):\n",
        "    N, H = len(price), len(P_h)\n",
        "    X = cp.Variable((N, H))\n",
        "    power = cp.multiply(X, P_h.reshape(1, H))\n",
        "    base_cost = cp.sum(cp.multiply(price.reshape(N, 1), power)) / 1000.0\n",
        "    constraints = [\n",
        "        cp.sum(power, axis=0) >= E_h,\n",
        "        cp.sum(power, axis=1) <= peak_limit,\n",
        "        X >= 0, X <= 1\n",
        "    ]\n",
        "    if guidance is not None:\n",
        "        guidance_penalty = lam * cp.sum_squares(X - guidance)\n",
        "        total_cost = base_cost + guidance_penalty\n",
        "    else:\n",
        "        total_cost = base_cost\n",
        "    prob = cp.Problem(cp.Minimize(total_cost), constraints)\n",
        "    prob.solve()\n",
        "    return X.value.astype(float)\n",
        "\n",
        "# 2) Dataset class\n",
        "class TSLSupervisedDatasetStructured(Dataset):\n",
        "    def __init__(self, n_samples, N, H):\n",
        "        self.prompts = []\n",
        "        self.targets = []\n",
        "        self.N, self.H = N, H\n",
        "        self.P_h = np.array([1000, 1500])\n",
        "        self.E_h = np.array([3000, 6000])\n",
        "        self.peak_range = (2000, 6000)\n",
        "\n",
        "        for _ in range(n_samples):\n",
        "            price = 0.05 + (0.2 - 0.05) * np.random.rand(N)\n",
        "            peak_limit = np.random.randint(*self.peak_range)\n",
        "            X_opt = generate_optimal_schedule(price, self.P_h, self.E_h, peak_limit)\n",
        "            self.prompts.append(self._build_prompt(price, peak_limit))\n",
        "            self.targets.append(torch.tensor(X_opt.flatten(), dtype=torch.float32))\n",
        "\n",
        "    def _build_prompt(self, price, peak_limit):\n",
        "        s = \"[Prices]\\n\" + \"\\n\".join(f\"Slot {i+1}: {p:.3f} $/kWh\" for i, p in enumerate(price))\n",
        "        s += \"\\n\\n[Appliances]\\n\"\n",
        "        for i, (pw, eg) in enumerate(zip(self.P_h, self.E_h), start=1):\n",
        "            s += f\"Appliance {i}:\\n  Rated Power: {pw/1000:.1f} kW\\n  Energy Required: {eg/1000:.1f} kWh\\n\"\n",
        "        s += f\"\\n[Peak Limit]\\n{peak_limit/1000:.1f} kW\\n\"\n",
        "        s += \"\\n[Objective]\\nMinimize total electricity cost.\\n\"\n",
        "        s += f\"\\n[Output]\\nProvide a {self.N}x{self.H} schedule matrix (0-1 values).\"\n",
        "        return s\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.prompts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.prompts[idx], self.targets[idx]\n",
        "\n",
        "# 3) DistilBERT Model\n",
        "class SupervisedTSLModelDistilBERT(nn.Module):\n",
        "    def __init__(self, N, H):\n",
        "        super().__init__()\n",
        "        self.tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "        self.distilbert = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
        "        hidden = self.distilbert.config.hidden_size\n",
        "        self.regressor = nn.Sequential(\n",
        "            nn.Linear(hidden, hidden // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden // 2, N * H)\n",
        "        )\n",
        "\n",
        "    def forward(self, prompts):\n",
        "        enc = self.tokenizer(prompts, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "        device = next(self.distilbert.parameters()).device\n",
        "        enc = {k: v.to(device) for k, v in enc.items()}\n",
        "        out = self.distilbert(**enc).last_hidden_state[:, 0, :]\n",
        "        return self.regressor(out)\n",
        "\n",
        "# 4) Training\n",
        "def train_model(model, dataset, epochs=30, batch_size=16, lr=2e-5):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "    optim = AdamW(model.parameters(), lr=lr)\n",
        "    loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    for ep in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        running = 0.0\n",
        "        for prompts, targets in loader:\n",
        "            logits = model(prompts).to(device)\n",
        "            loss = loss_fn(logits, targets.to(device))\n",
        "            optim.zero_grad()\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            running += loss.item() * targets.size(0)\n",
        "        print(f\"Epoch {ep}/{epochs} â€” Avg Loss: {running/len(dataset):.6f}\")\n",
        "    return model\n",
        "\n",
        "# 5) Test and plot\n",
        "def test_and_plot(model, tests=5, N=25):\n",
        "    P_h = np.array([1000, 1500])\n",
        "    E_h = np.array([3000, 6000])\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.eval().to(device)\n",
        "\n",
        "    for t_i in range(1, tests + 1):\n",
        "        price = 0.05 + (0.2 - 0.05) * np.random.rand(N)\n",
        "        peak = np.random.randint(2000, 6000)\n",
        "\n",
        "        # Prompt\n",
        "        p = \"[Prices]\\n\" + \"\\n\".join(f\"Slot {i+1}: {v:.3f} $/kWh\" for i, v in enumerate(price))\n",
        "        p += \"\\n\\n[Appliances]\\n\"\n",
        "        for i, (pw, eg) in enumerate(zip(P_h, E_h), start=1):\n",
        "            p += (f\"Appliance {i}:\\n\"\n",
        "                  f\"  Rated Power: {pw/1000:.1f} kW\\n\"\n",
        "                  f\"  Energy Required: {eg/1000:.1f} kWh\\n\")\n",
        "        p += f\"\\n[Peak Limit]\\n{peak/1000:.1f} kW\\n\"\n",
        "        p += \"\\n[Objective]\\nMinimize total electricity cost.\\n\"\n",
        "        p += f\"\\n[Output]\\nProvide a {N}x2 schedule matrix (0-1 values).\"\n",
        "\n",
        "        # Predict with DistilBERT\n",
        "        with torch.no_grad():\n",
        "            enc = model.tokenizer([p], padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
        "            out = model.distilbert(**enc).last_hidden_state[:, 0, :]\n",
        "            logits = model.regressor(out)\n",
        "            probs = torch.sigmoid(logits).cpu().numpy()[0].reshape(N, 2)\n",
        "        distil_sched = probs.astype(float)\n",
        "\n",
        "        # Solve optimal\n",
        "        opt_sched = generate_optimal_schedule(price, P_h, E_h, peak)\n",
        "\n",
        "        # Plot DistilBERT\n",
        "        t = np.arange(N)\n",
        "        fig, ax = plt.subplots(figsize=(10, 3))\n",
        "        ax.bar(t, distil_sched[:, 0]*P_h[0], label=\"Appliance 1\")\n",
        "        ax.bar(t, distil_sched[:, 1]*P_h[1], bottom=distil_sched[:, 0]*P_h[0], label=\"Appliance 2\")\n",
        "        ax.axhline(peak, color='r', ls='--', label=\"Peak Limit\")\n",
        "        ax.set_title(f\"DistilBERT Schedule (Test {t_i})\")\n",
        "        ax.set_xlabel(\"Time Slot\")\n",
        "        ax.set_ylabel(\"Power (W)\")\n",
        "        ax.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(f'distilbert_schedule_test_{t_i}.png')\n",
        "        plt.close()\n",
        "\n",
        "        # Plot Optimal\n",
        "        fig, ax = plt.subplots(figsize=(10, 3))\n",
        "        ax.bar(t, opt_sched[:, 0]*P_h[0], label=\"Appliance 1\")\n",
        "        ax.bar(t, opt_sched[:, 1]*P_h[1], bottom=opt_sched[:, 0]*P_h[0], label=\"Appliance 2\")\n",
        "        ax.axhline(peak, color='r', ls='--', label=\"Peak Limit\")\n",
        "        ax.set_title(f\"Optimal Schedule (Test {t_i})\")\n",
        "        ax.set_xlabel(\"Time Slot\")\n",
        "        ax.set_ylabel(\"Power (W)\")\n",
        "        ax.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(f'optimal_schedule_test_{t_i}.png')\n",
        "        plt.close()\n",
        "\n",
        "        # Cost & Energy Summary\n",
        "        cost_distil = (price[:, None] * (distil_sched * P_h) / 1000.0).sum()\n",
        "        cost_opt = (price[:, None] * (opt_sched * P_h) / 1000.0).sum()\n",
        "\n",
        "        energy_distil = (distil_sched * P_h).sum(axis=0) / 1000.0\n",
        "        energy_opt = (opt_sched * P_h).sum(axis=0) / 1000.0\n",
        "\n",
        "        print(f\"Test {t_i}:\")\n",
        "        print(f\"  DistilBERT Cost: ${cost_distil:.2f}\")\n",
        "        print(f\"  Optimal Cost: ${cost_opt:.2f}\")\n",
        "        print(f\"  Cost Gap: ${cost_distil - cost_opt:.2f}\")\n",
        "        print(f\"  Energy (DistilBERT): Appliance 1 = {energy_distil[0]:.2f} kWh, Appliance 2 = {energy_distil[1]:.2f} kWh\")\n",
        "        print(f\"  Energy (Optimal): Appliance 1 = {energy_opt[0]:.2f} kWh, Appliance 2 = {energy_opt[1]:.2f} kWh\\n\")\n",
        "\n",
        "# 6) Entry\n",
        "if __name__ == \"__main__\":\n",
        "    N, H = 25, 2\n",
        "    ds = TSLSupervisedDatasetStructured(2000, N, H)\n",
        "\n",
        "    # Train DistilBERT model\n",
        "    print(\"Training DistilBERT model...\")\n",
        "    model = SupervisedTSLModelDistilBERT(N, H)\n",
        "    model = train_model(model, ds, epochs=30, batch_size=16, lr=2e-5)\n",
        "\n",
        "    # Test and plot\n",
        "    test_and_plot(model, tests=5, N=N)"
      ]
    }
  ]
}